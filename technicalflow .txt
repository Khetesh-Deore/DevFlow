# Detailed Technical Flow for DevFlow Platform

Based on your existing implementation (sandbox + scraper done), here's the complete technical flow to build the full platform.

---

## PHASE 1: UNDERSTANDING YOUR EXISTING COMPONENTS

### What You Already Have:
1. **Scraper Service** - Fetches problems from LeetCode, Codeforces, HackerRank, GFG, CodeChef
2. **Sandbox Service** - Secure Docker-based code execution with resource limits
3. **Basic Backend Structure** - Express API with MongoDB

### What You Need to Build:
1. **User Authentication & Authorization System**
2. **Contest Management System**
3. **Real-time Features (Socket.io)**
4. **Anti-Cheat System**
5. **Leaderboard System**
6. **Frontend Application**
7. **Integration Layer** (connecting everything together)

---

## PHASE 2: AUTHENTICATION & USER MANAGEMENT FLOW

### 2.1 User Registration Flow

**Technical Flow:**
```
User fills form → Frontend validation → POST /api/auth/register
→ Backend validates input → Check if user exists in MongoDB
→ Hash password with bcrypt → Create user document in MongoDB
→ Generate JWT token → Set httpOnly cookie/localStorage
→ Return user data + token → Redirect to dashboard
```

**Database Schema (MongoDB):**
```javascript
User Collection {
  _id: ObjectId,
  username: String (unique, indexed),
  email: String (unique, indexed),
  password: String (hashed),
  role: String ('admin' | 'participant'),
  profile: {
    avatar: String,
    bio: String,
    rating: Number (default: 1500),
    country: String
  },
  stats: {
    contestsParticipated: Number,
    problemsSolved: Number,
    totalSubmissions: Number,
    acceptedSubmissions: Number
  },
  createdAt: Date,
  updatedAt: Date
}
```

**Implementation Steps:**
1. Create User model in `models/User.js`
2. Add pre-save middleware to hash password
3. Add method to generate JWT token
4. Add method to compare passwords
5. Create auth controller with register/login/logout functions
6. Create auth middleware to protect routes
7. Create role-based authorization middleware

### 2.2 Login Flow

**Technical Flow:**
```
User enters credentials → POST /api/auth/login
→ Find user by email → Compare password hash
→ If valid: Generate JWT token → Set cookie/localStorage
→ Return user data + token → Redirect to dashboard
→ If invalid: Return 401 error
```

### 2.3 Protected Route Flow

**Technical Flow:**
```
User makes request to protected endpoint
→ Extract token from header/cookie
→ Verify JWT token → Decode token
→ Fetch user from MongoDB using decoded ID
→ Attach user to request object (req.user)
→ Check role if needed (admin/participant)
→ If valid: Continue to route handler
→ If invalid: Return 401/403 error
```

---

## PHASE 3: CONTEST MANAGEMENT SYSTEM

### 3.1 Contest Creation Flow (Admin)

**Technical Flow:**
```
Admin navigates to Create Contest page
→ Fills multi-step form (basic info, settings, questions)
→ On "Add Question via URL":
  → Admin pastes problem URL
  → Frontend detects platform (regex pattern matching)
  → POST /api/problems/scrape { url, platform }
  → Backend calls your existing scraper service
  → Scraper fetches problem details
  → Gemini AI generates additional test cases
  → Problem saved to MongoDB with source URL
  → Return problem ID to frontend
  → Frontend adds to "selected questions" list
→ Admin configures anti-cheat settings
→ Admin clicks "Schedule Contest"
→ POST /api/contests with all data
→ Backend validates ownership (admin role)
→ Check customUrl uniqueness
→ Create Contest document in MongoDB
→ Link questions to contest
→ Set up cron job for auto-start (node-cron)
→ Return contest data
→ Redirect to contest dashboard
```

**Database Schema:**
```javascript
Contest Collection {
  _id: ObjectId,
  title: String,
  description: String,
  customUrl: String (unique, indexed, slugified),
  createdBy: ObjectId (ref: 'User'),
  startTime: Date (indexed),
  endTime: Date (indexed),
  duration: Number (minutes),
  status: String ('draft' | 'scheduled' | 'live' | 'ended'),
  questions: [ObjectId] (ref: 'Problem'),
  participants: [{
    userId: ObjectId (ref: 'User'),
    registeredAt: Date,
    score: Number,
    solvedQuestions: [ObjectId],
    submissions: [ObjectId],
    rank: Number,
    violations: [{
      type: String,
      timestamp: Date,
      count: Number
    }]
  }],
  settings: {
    visibility: String ('public' | 'private'),
    maxTabSwitches: Number (default: 3),
    enableProctoring: Boolean,
    disableCopyPaste: Boolean,
    showLeaderboard: Boolean
  },
  createdAt: Date,
  updatedAt: Date
}

// Compound index for faster queries
Index: { status: 1, startTime: -1 }
```

### 3.2 Problem Import Flow (Integration with Your Scraper)

**Technical Flow:**
```
POST /api/problems/scrape
→ Validate URL format
→ Detect platform (leetcode.com, codeforces.com, etc.)
→ Call platform-specific scraper:
  
  YOUR EXISTING SCRAPER FLOW:
  → Selenium WebDriver launches headless browser
  → Navigate to problem URL
  → Extract DOM elements:
    - Title (h1, .title, etc.)
    - Description (problem statement div)
    - Examples (input/output blocks)
    - Constraints (constraints section)
    - Test cases (if visible)
  → Parse HTML to clean text
  → Structure data into standardized format
  
→ ENHANCE WITH AI (Gemini):
  → Send problem description to Gemini API
  → Prompt: "Generate 5 edge case test cases for this problem"
  → Receive AI-generated test cases
  → Validate test case format
  
→ Save to MongoDB:
  → Create Problem document
  → Save original scraped data
  → Save AI-generated test cases
  → Mark as "imported" with source URL
  
→ Return problem ID and preview data
```

**Database Schema:**
```javascript
Problem Collection {
  _id: ObjectId,
  title: String (indexed),
  slug: String (unique, indexed),
  description: String (rich text/HTML),
  difficulty: String ('easy' | 'medium' | 'hard'),
  source: {
    platform: String ('leetcode' | 'codeforces' | 'hackerrank' | 'gfg' | 'codechef' | 'custom'),
    url: String,
    problemId: String (original platform ID)
  },
  constraints: String,
  inputFormat: String,
  outputFormat: String,
  sampleTestCases: [{
    input: String,
    output: String,
    explanation: String
  }],
  hiddenTestCases: [{
    _id: ObjectId,
    input: String,
    output: String,
    weight: Number (for scoring)
  }],
  limits: {
    timeLimit: Number (seconds),
    memoryLimit: Number (MB)
  },
  points: Number,
  tags: [String],
  createdBy: ObjectId (ref: 'User'),
  stats: {
    totalSubmissions: Number,
    acceptedSubmissions: Number,
    successRate: Number
  },
  createdAt: Date,
  updatedAt: Date
}
```

### 3.3 Contest Status Management Flow

**Technical Flow using Cron Jobs:**
```
CRON JOB RUNS EVERY MINUTE:

Check Scheduled Contests:
→ Find contests where status = 'scheduled' AND startTime <= now
→ For each contest:
  → Update status to 'live'
  → Emit Socket.io event to all connected clients:
    io.emit('contest-started', { contestId, title })
  → Send email notifications to registered participants
  → Log event

Check Live Contests:
→ Find contests where status = 'live' AND endTime <= now
→ For each contest:
  → Update status to 'ended'
  → Freeze leaderboard (make final calculations)
  → Generate contest results
  → Calculate final rankings
  → Update participant ratings
  → Emit Socket.io event:
    io.to(contestId).emit('contest-ended', { contestId })
  → Send result emails
  → Archive submissions
  → Log event
```

**Implementation:**
```javascript
// services/cronService.js
const cron = require('node-cron');

// Run every minute
cron.schedule('* * * * *', async () => {
  await checkScheduledContests();
  await checkLiveContests();
});
```

---

## PHASE 4: CODE SUBMISSION & EXECUTION FLOW

### 4.1 Complete Submission Flow (Integration with Your Sandbox)

**Technical Flow:**
```
USER SUBMITS CODE:

Frontend:
→ User writes code in Monaco Editor
→ Selects language from dropdown
→ Clicks "Submit" button
→ Disable submit button (prevent double submission)
→ Show loading state
→ POST /api/contests/:contestId/problems/:problemId/submit
  Body: { code, language }
  Headers: { Authorization: JWT }

Backend API:
→ Authenticate user (JWT middleware)
→ Validate contest is live
→ Validate user is registered
→ Validate problem exists in contest
→ Check for forbidden keywords (security)
→ Check code length limits
→ Create Submission document in MongoDB:
  {
    _id: ObjectId,
    contestId: contestId,
    problemId: problemId,
    userId: userId,
    code: code,
    language: language,
    status: 'pending',
    createdAt: Date.now()
  }
→ Add submission to Bull Queue:
  submissionQueue.add({
    submissionId: submission._id,
    code: code,
    language: language,
    problemId: problemId,
    testCases: problem.hiddenTestCases
  })
→ Return submission ID immediately
→ Response: { submissionId, status: 'pending' }

BULL QUEUE PROCESSOR (Background Job):
→ Picks up job from queue
→ Fetch problem details (test cases, limits)
→ Prepare execution request for YOUR SANDBOX:

CALL YOUR EXISTING SANDBOX SERVICE:
→ POST http://localhost:3001/api/sandbox/run
  Body: {
    code: userCode,
    language: language,
    testCases: [
      { input: "1 2", expectedOutput: "3" },
      { input: "5 5", expectedOutput: "10" }
    ],
    limits: {
      timeLimit: 2000, // ms
      memoryLimit: 256 // MB
    }
  }

YOUR SANDBOX EXECUTION:
→ Validate input
→ Create temporary directory for this execution
→ Write code to file
→ Select Docker image based on language:
  - Python: python:3.9-alpine
  - C++: gcc:11-alpine
  - Java: openjdk:11-slim
  - JavaScript: node:16-alpine
  
→ For each test case:
  → Spin up Docker container with security:
    docker run --rm \
      --network none \              # No network
      --memory 256m \                # Memory limit
      --cpus 0.5 \                   # CPU limit
      --read-only \                  # Read-only filesystem
      --tmpfs /tmp \                 # Temp directory
      --user nobody \                # Non-root user
      --pids-limit 50 \              # Process limit
      -v /path/to/code:/code:ro \   # Mount code read-only
      python:3.9-alpine \
      timeout 2s python /code/solution.py < input.txt
  
  → Execute code with test case input
  → Capture stdout, stderr, exit code
  → Measure execution time
  → Measure memory usage
  → Compare output with expected output:
    - Strip whitespace
    - Normalize line endings
    - Case-sensitive comparison
  → Store result: { passed: true/false, time, memory }
  → Clean up container
  
→ Aggregate results:
  - Count passed test cases
  - Determine verdict:
    * All passed → AC (Accepted)
    * Some failed → WA (Wrong Answer)
    * Time exceeded → TLE (Time Limit Exceeded)
    * Runtime error → RE (Runtime Error)
    * Compilation failed → CE (Compilation Error)
  - Calculate score: (passedCount / totalCount) * points
  
→ Return results to API backend:
  {
    status: 'AC',
    passedTestCases: 8,
    totalTestCases: 10,
    executionTime: 145, // ms
    memoryUsed: 23.5, // MB
    testCaseResults: [
      { testCaseId, passed: true, time: 12, memory: 2.1 },
      ...
    ]
  }

BACK TO BACKEND:
→ Receive sandbox results
→ Update Submission document in MongoDB:
  {
    status: 'AC',
    testCasesPassed: 8,
    totalTestCases: 10,
    executionTime: 145,
    memoryUsed: 23.5,
    score: 80,
    verdict: 'accepted',
    completedAt: Date.now()
  }

→ Update Contest participant score:
  - Find participant in contest.participants array
  - Add score if not already solved
  - If better score, update
  - Add to solvedQuestions array
  
→ Update Problem stats:
  - Increment totalSubmissions
  - If AC: increment acceptedSubmissions
  - Recalculate successRate

→ Trigger Leaderboard Update:
  - Recalculate user's rank
  - Update Redis cache
  - Emit Socket.io event:
    io.to(contestId).emit('leaderboard-update', updatedLeaderboard)

→ Emit submission result to user:
  io.to(`user-${userId}`).emit('submission-result', {
    submissionId,
    status: 'AC',
    score: 80,
    passedTests: 8,
    totalTests: 10,
    executionTime: 145,
    memoryUsed: 23.5
  })

Frontend (Real-time Update):
→ Socket.io listener receives result
→ Show result modal with verdict
→ Update UI:
  - Problem status badge (unsolved → solved)
  - User score in header
  - Submission history list
→ Show confetti animation if AC
→ Update leaderboard in real-time
```

**Database Schema:**
```javascript
Submission Collection {
  _id: ObjectId,
  contestId: ObjectId (ref: 'Contest', indexed),
  problemId: ObjectId (ref: 'Problem', indexed),
  userId: ObjectId (ref: 'User', indexed),
  code: String,
  language: String,
  status: String ('pending' | 'running' | 'AC' | 'WA' | 'TLE' | 'RE' | 'CE'),
  verdict: String,
  testCasesPassed: Number,
  totalTestCases: Number,
  executionTime: Number (ms),
  memoryUsed: Number (MB),
  score: Number,
  testCaseResults: [{
    testCaseId: ObjectId,
    passed: Boolean,
    executionTime: Number,
    memoryUsed: Number,
    output: String (only if failed),
    expectedOutput: String (only if failed),
    error: String
  }],
  submittedAt: Date,
  completedAt: Date
}

// Compound indexes for performance
Index: { userId: 1, contestId: 1, submittedAt: -1 }
Index: { contestId: 1, problemId: 1 }
Index: { status: 1 } // For pending submissions queue
```

---

## PHASE 5: ANTI-CHEAT SYSTEM FLOW

### 5.1 Client-Side Monitoring Flow

**Technical Flow:**
```
WHEN USER ENTERS CONTEST:

Frontend Initialization:
→ User clicks "Enter Contest" button
→ Request fullscreen mode:
  document.documentElement.requestFullscreen()
→ Initialize AntiCheatMonitor service
→ Connect to Socket.io server:
  socket.emit('join-contest', { contestId, userId })
→ Start monitoring:
  
  TAB SWITCH DETECTION:
  → Add visibility change listener:
    document.addEventListener('visibilitychange', handleVisibilityChange)
  → On tab switch (document.hidden = true):
    - Increment local violation count
    - Emit to server:
      socket.emit('violation', {
        type: 'tab_switch',
        contestId,
        timestamp: Date.now()
      })
    - Show warning modal
  
  WINDOW BLUR DETECTION:
  → Add blur listener:
    window.addEventListener('blur', handleWindowBlur)
  → On window blur:
    - Check if fullscreen exited
    - Emit violation if not just tab switch
  
  COPY-PASTE PREVENTION:
  → Monaco Editor configuration:
    editor.updateOptions({
      contextmenu: false,
      quickSuggestions: false
    })
  → Add keyboard event listener:
    editor.onKeyDown((e) => {
      if ((e.ctrlKey || e.metaKey) && 
          (e.keyCode === 67 || e.keyCode === 86)) {
        e.preventDefault()
        showWarning('Copy-paste disabled')
        emitViolation('copy_paste_attempt')
      }
    })
  
  FULLSCREEN EXIT DETECTION:
  → Add fullscreen change listener:
    document.addEventListener('fullscreenchange', handleFullscreenChange)
  → On exit:
    - Show immediate warning
    - Request fullscreen again
    - Emit violation after 3 seconds if not re-entered
  
  SUSPICIOUS PATTERNS:
  → Track typing patterns:
    - Calculate WPM (words per minute)
    - Detect sudden paste-like behavior (100+ chars in <1s)
    - Emit suspicious activity if detected

VIOLATION HANDLING:
→ On each violation:
  - Store in local state
  - Show non-dismissible warning modal
  - Update warning count display
  - If count >= maxAllowed:
    - Lock submit button
    - Show "Submissions Locked" screen
    - Disable code editor
```

### 5.2 Server-Side Violation Tracking Flow

**Technical Flow:**
```
SOCKET.IO EVENT HANDLER:

socket.on('violation', async (data) => {
  → Validate socket is authenticated
  → Extract userId from socket.user
  → Validate contest is live
  
  → Find or create Violation document:
    {
      userId,
      contestId,
      type: data.type,
      violations: [{
        timestamp: data.timestamp,
        metadata: data.metadata
      }]
    }
  
  → Increment violation count for this type
  → Fetch contest anti-cheat settings
  → Check if threshold exceeded:
    if (violationCount >= contest.settings.maxTabSwitches) {
      → Update user status in Contest document:
        contestants[userId].locked = true
      → Emit lock event to user:
        io.to(`user-${userId}`).emit('submissions-locked', {
          reason: 'Too many violations',
          type: data.type,
          count: violationCount
        })
      → Notify admins in real-time:
        io.to('admin-room').emit('user-locked', {
          userId,
          contestId,
          reason
        })
      → Log to admin dashboard
    } else {
      → Emit warning to user:
        io.to(`user-${userId}`).emit('violation-warning', {
          type: data.type,
          count: violationCount,
          maxAllowed: contest.settings.maxTabSwitches,
          remainingWarnings: maxAllowed - count
        })
    }
  
  → Store violation in database
  → Update violation count in Redis (faster lookups)
})
```

**Database Schema:**
```javascript
Violation Collection {
  _id: ObjectId,
  userId: ObjectId (ref: 'User', indexed),
  contestId: ObjectId (ref: 'Contest', indexed),
  type: String ('tab_switch' | 'window_blur' | 'copy_paste' | 'fullscreen_exit' | 'suspicious_activity'),
  violations: [{
    timestamp: Date,
    metadata: Object (device info, browser, etc.)
  }],
  totalCount: Number,
  status: String ('warned' | 'locked'),
  createdAt: Date,
  updatedAt: Date
}

// Compound index
Index: { userId: 1, contestId: 1, type: 1 }
```

---

## PHASE 6: LEADERBOARD SYSTEM FLOW

### 6.1 Real-Time Leaderboard Calculation Flow

**Technical Flow:**
```
TRIGGERED AFTER EVERY SUCCESSFUL SUBMISSION:

In Submission Queue Processor (after sandbox returns):
→ Calculate user's new score in contest
→ Call LeaderboardService.updateUserScore()

LeaderboardService.updateUserScore(userId, contestId):
→ Fetch all user's AC submissions in this contest
→ Calculate total score (sum of unique solved problems)
→ Calculate total time (time from contest start to last AC)
→ Apply penalties if configured (wrong submissions)
→ Update user's entry in Redis sorted set:
  
  REDIS STRUCTURE:
  Key: `leaderboard:${contestId}`
  Type: Sorted Set (ZADD)
  
  Score calculation for sorting:
  score = (userScore * 1000000) - totalTime
  // Higher score = better rank
  // If tied, less time = better rank
  
  ZADD leaderboard:contest123 5000145 "user456"
  // 5000 points, 145 seconds total time
  
→ Recalculate ranks for all users:
  ZREVRANGE leaderboard:contest123 0 -1 WITHSCORES
  → Returns sorted list by score descending
  → Assign ranks (1, 2, 3, ...)
  → Handle ties (same score & time = same rank)

→ Prepare leaderboard update payload:
  {
    contestId,
    topUsers: top10UsersArray,
    updatedUser: {
      userId,
      username,
      score,
      rank,
      solvedProblems,
      lastSubmissionTime
    }
  }

→ Emit Socket.io event to all in contest room:
  io.to(`contest-${contestId}`).emit('leaderboard-update', payload)

→ Cache full leaderboard in Redis:
  Key: `leaderboard:full:${contestId}`
  Value: JSON.stringify(fullLeaderboardArray)
  TTL: 10 seconds
  
→ Return updated leaderboard
```

### 6.2 Leaderboard Retrieval Flow

**Technical Flow:**
```
USER REQUESTS LEADERBOARD:

GET /api/contests/:contestId/leaderboard?page=1&limit=50

Backend:
→ Authenticate user
→ Check Redis cache first:
  const cached = await redis.get(`leaderboard:full:${contestId}`)
  if (cached) return JSON.parse(cached)

→ If not cached, calculate from database:
  → Fetch contest with participants
  → For each participant:
    - Fetch all AC submissions
    - Calculate total score
    - Calculate total time
    - Count solved problems
  → Sort by score DESC, time ASC
  → Assign ranks
  → Cache result in Redis (TTL: 10s)
  → Return paginated result

→ Return response:
  {
    leaderboard: [
      {
        rank: 1,
        userId,
        username,
        avatar,
        score: 850,
        solvedProblems: 5,
        totalTime: 3245, // seconds
        lastSubmission: timestamp
      },
      ...
    ],
    currentUser: {
      rank: 45,
      score: 320,
      ...
    },
    totalParticipants: 250,
    page: 1,
    totalPages: 5
  }
```

### 6.3 Per-Problem Leaderboard Flow

**Technical Flow:**
```
GET /api/contests/:contestId/problems/:problemId/leaderboard

→ Fetch all AC submissions for this problem in contest
→ Sort by:
  1. Execution time (fastest first)
  2. Memory used (less first)
  3. Submission time (earliest first)
→ Assign ranks
→ Return:
  {
    problemTitle,
    leaderboard: [
      {
        rank: 1,
        userId,
        username,
        executionTime: 45, // ms
        memoryUsed: 12.3, // MB
        submissionTime: timestamp,
        language: 'cpp'
      },
      ...
    ]
  }
```

---

## PHASE 7: REAL-TIME FEATURES INTEGRATION

### 7.1 Socket.io Architecture

**Technical Flow:**
```
SERVER SETUP (server.js):

const io = require('socket.io')(server, {
  cors: { origin: process.env.CLIENT_URL }
})

// Authentication middleware
io.use(async (socket, next) => {
  const token = socket.handshake.auth.token
  if (!token) return next(new Error('Auth failed'))
  
  const decoded = jwt.verify(token, process.env.JWT_SECRET)
  const user = await User.findById(decoded.id)
  socket.user = user
  next()
})

// Connection handler
io.on('connection', (socket) => {
  console.log('User connected:', socket.user.id)
  
  // User joins personal room
  socket.join(`user-${socket.user.id}`)
  
  // User joins contest room
  socket.on('join-contest', (contestId) => {
    socket.join(`contest-${contestId}`)
    socket.contestId = contestId
    
    // Broadcast to others in room
    socket.to(`contest-${contestId}`).emit('user-joined', {
      userId: socket.user.id,
      username: socket.user.username
    })
    
    // Send current participant count
    const roomSize = io.sockets.adapter.rooms.get(`contest-${contestId}`).size
    io.to(`contest-${contestId}`).emit('participant-count', roomSize)
  })
  
  // Handle disconnection
  socket.on('disconnect', () => {
    if (socket.contestId) {
      const roomSize = io.sockets.adapter.rooms.get(`contest-${socket.contestId}`)?.size || 0
      io.to(`contest-${socket.contestId}`).emit('participant-count', roomSize)
    }
  })
})

Export io for use in other files
```

### 7.2 Real-Time Events Flow

**Technical Flow:**
```
EVENT TYPES AND USAGE:

1. SUBMISSION RESULT:
Triggered: After sandbox completes execution
Emitter: Submission queue processor
Receiver: Individual user
Code:
  io.to(`user-${userId}`).emit('submission-result', {
    submissionId,
    status,
    score,
    details
  })

2. LEADERBOARD UPDATE:
Triggered: After submission score calculated
Emitter: Leaderboard service
Receiver: All users in contest
Code:
  io.to(`contest-${contestId}`).emit('leaderboard-update', {
    topUsers,
    updatedUser
  })
Throttle: Max 1 update per second per contest

3. VIOLATION WARNING:
Triggered: On anti-cheat violation
Emitter: Violation handler
Receiver: Individual user
Code:
  io.to(`user-${userId}`).emit('violation-warning', {
    type,
    count,
    maxAllowed
  })

4. CONTEST STATUS CHANGE:
Triggered: Cron job (contest start/end)
Emitter: Cron service
Receiver: All registered users
Code:
  io.emit('contest-started', { contestId, title })
  io.to(`contest-${contestId}`).emit('contest-ended', {})

5. LIVE SUBMISSION FEED:
Triggered: On every submission
Emitter: Submission processor
Receiver: All in contest (admin dashboard)
Code:
  io.to(`contest-${contestId}`).emit('new-submission', {
    userId,
    username,
    problemId,
    status,
    timestamp
  })

6. RANK CHANGE NOTIFICATION:
Triggered: When user rank changes significantly
Emitter: Leaderboard service
Receiver: Individual user
Code:
  io.to(`user-${userId}`).emit('rank-changed', {
    oldRank,
    newRank,
    difference
  })
```

---

## PHASE 8: FRONTEND ARCHITECTURE & DATA FLOW

### 8.1 Frontend State Management Flow

**Technical Flow using Redux:**

```
REDUX STORE STRUCTURE:

store/
├── slices/
│   ├── authSlice.js       // user, token, isAuthenticated
│   ├── contestsSlice.js   // contests, currentContest, loading
│   ├── problemsSlice.js   // problems, currentProblem
│   ├── submissionsSlice.js// submissions, currentSubmission
│   ├── leaderboardSlice.js// leaderboard, userRank
│   └── socketSlice.js     // connection status, events
└── store.js

REDUX FLOW EXAMPLE (Fetching Contest):

User navigates to /contest/summer-code-2025
→ React Router renders ContestDetails component
→ useEffect hook dispatches:
  dispatch(fetchContestByUrl('summer-code-2025'))

→ Redux Thunk (async action):
  export const fetchContestByUrl = createAsyncThunk(
    'contests/fetchByUrl',
    async (customUrl) => {
      const response = await contestService.getByUrl(customUrl)
      return response.data
    }
  )

→ contestsSlice reducers handle states:
  - pending: Set loading = true
  - fulfilled: Set currentContest = payload, loading = false
  - rejected: Set error, loading = false

→ Component re-renders with new state
→ Display contest details

SOCKET.IO INTEGRATION WITH REDUX:

socketMiddleware.js:
export const socketMiddleware = (store) => {
  const socket = io(process.env.REACT_APP_API_URL)
  
  socket.on('connect', () => {
    store.dispatch(socketConnected())
  })
  
  socket.on('leaderboard-update', (data) => {
    store.dispatch(updateLeaderboard(data))
  })
  
  socket.on('submission-result', (data) => {
    store.dispatch(submissionCompleted(data))
    // Show toast notification
    toast.success(`Submission ${data.status}!`)
  })
  
  return (next) => (action) => {
    if (action.type === 'socket/emit') {
      socket.emit(action.payload.event, action.payload.data)
    }
    return next(action)
  }
}
```

### 8.2 Contest Arena Component Flow

**Technical Flow:**
```
COMPONENT HIERARCHY:

ContestArena (Page)
├── ContestHeader (Timer, Score, Rank)
├── ProblemSidebar (Problem List)
├── MainContent (Split View)
│   ├── ProblemDescription (Top)
│   └── CodeEditor (Bottom - Monaco Editor)
└── SubmissionPanel (Right)
    ├── TestCaseSection
    ├── OutputDisplay
    └── SubmissionHistory

COMPONENT INTERACTION FLOW:

1. ContestArena mounts:
→ Fetch contest data
→ Connect to Socket.io
→ Join contest room
→ Initialize anti-cheat monitoring
→ Load problems
→ Restore code from localStorage (if exists)

2. User selects problem:
→ ProblemSidebar onClick
→ Update selectedProblem in state
→ Load problem details
→ Load user's previous submissions
→ Load or clear editor based on localStorage

3. User
writes code:
→ Monaco Editor onChange
→ Debounce updates (500ms)
→ Auto-save to localStorage:
  Key: `code-${contestId}-${problemId}-${language}`
→ Enable "Run Code" and "Submit" buttons

4. User clicks "Run Code":
→ Disable button, show loading
→ POST /api/sandbox/run (your sandbox)
  Body: { code, language, testCases: sampleTestCases }
→ Display results in OutputDisplay component
→ Show pass/fail for each sample test case
→ Re-enable button

5. User clicks "Submit":
→ Disable button
→ Show confirmation modal
→ User confirms
→ POST /api/contests/:id/problems/:id/submit
→ Backend returns submissionId
→ Show "Judging..." status
→ Wait for Socket.io 'submission-result' event
→ Display result modal with verdict
→ Update UI (score, problem status, leaderboard)
→ Re-enable submit button

6. Real-time updates:
→ Socket.io listeners update Redux store
→ Components re-render automatically
→ Leaderboard updates smoothly
→ Rank changes animate
→ Notifications appear

7. Anti-cheat triggers:
→ Tab switch detected
→ Show warning modal (non-dismissible, 3-second timer)
→ Emit violation via Socket.io
→ Receive confirmation from server
→ Update violation count display
→ If locked: Show overlay, disable editor
```

---

## PHASE 9: ADMIN DASHBOARD FLOW

### 9.1 Real-Time Contest Monitoring Flow

**Technical Flow:**
```
ADMIN OPENS CONTEST MONITOR DASHBOARD:

Frontend:
→ Navigate to /admin/contests/:id/monitor
→ Authenticate admin role
→ Connect to Socket.io with admin credentials
→ Join admin room: socket.emit('join-admin-room', contestId)

Backend Socket Handler:
→ Verify admin role
→ Add socket to `admin-${contestId}` room
→ Send initial data:
  socket.emit('monitor-init', {
    participants: currentParticipants,
    submissions: recentSubmissions,
    violations: allViolations,
    stats: contestStats
  })

Real-Time Data Streams:

1. LIVE SUBMISSION FEED:
→ Every submission triggers:
  io.to(`admin-${contestId}`).emit('new-submission', {
    timestamp,
    userId,
    username,
    problemId,
    problemTitle,
    language,
    status: 'pending'
  })
→ Admin dashboard shows in activity feed
→ When result available:
  io.to(`admin-${contestId}`).emit('submission-update', {
    submissionId,
    status: 'AC',
    score
  })

2. VIOLATION ALERTS:
→ On violation detection:
  io.to(`admin-${contestId}`).emit('violation-alert', {
    userId,
    username,
    type: 'tab_switch',
    count: 2,
    timestamp
  })
→ Admin dashboard shows notification badge
→ Violation list updates in real-time

3. LEADERBOARD LIVE VIEW:
→ Same leaderboard-update events
→ Admin sees all participants
→ Can filter/search
→ Click user to see details

ADMIN ACTIONS:

1. Warn User:
→ Admin clicks "Warn" button
→ POST /api/admin/contests/:id/warn-user
  Body: { userId, reason }
→ Backend emits to user:
  io.to(`user-${userId}`).emit('admin-warning', {
    message: reason,
    from: 'Contest Admin'
  })
→ User sees modal with warning

2. Lock User Submissions:
→ Admin clicks "Lock User"
→ POST /api/admin/contests/:id/lock-user
→ Backend updates contest document
→ Emit to user:
  io.to(`user-${userId}`).emit('submissions-locked', {
    reason: 'Locked by admin'
  })
→ User's submit button disabled

3. Broadcast Announcement:
→ Admin types message and clicks "Broadcast"
→ POST /api/admin/contests/:id/broadcast
→ Backend emits to all:
  io.to(`contest-${contestId}`).emit('announcement', {
    message,
    timestamp,
    type: 'warning'
  })
→ All users see notification banner

4. End Contest Early:
→ Admin clicks "End Contest"
→ Confirmation modal
→ POST /api/admin/contests/:id/end
→ Backend:
  - Update status to 'ended'
  - Freeze leaderboard
  - Calculate results
  - Emit:
    io.to(`contest-${contestId}`).emit('contest-ended', {
      reason: 'Ended by admin'
    })
→ All users redirected to results page
```

---

## PHASE 10: DEPLOYMENT ARCHITECTURE

### 10.1 Complete Deployment Flow

**Architecture:**
```
┌─────────────────────────────────────────────────────────┐
│                        CLIENT                           │
│  (Vercel - Static React Build)                          │
│  https://devflow.vercel.app                            │
└────────────────┬────────────────────────────────────────┘
                 │
                 │ HTTPS Requests
                 │
┌────────────────▼────────────────────────────────────────┐
│                      CDN (Cloudflare)                   │
│  - Cache static assets                                  │
│  - DDoS protection                                      │
│  - SSL termination                                      │
└────────────────┬────────────────────────────────────────┘
                 │
     ┌───────────┴───────────┐
     │                       │
     │ API Requests     WebSocket
     │                       │
┌────▼───────────────┐  ┌───▼──────────────────┐
│   BACKEND API      │  │   Socket.io Server   │
│   (Render/Railway) │  │   (Same instance)    │
│   api.devflow.com  │  │   ws.devflow.com     │
│                    │  │                      │
│ - Express.js       │  │ - Real-time events   │
│ - Authentication   │  │ - Room management    │
│ - Contest logic    │  │                      │
│ - Scraper calls    │  │                      │
└────┬───────────────┘  └──────────────────────┘
     │
     │
     ├───────────┬───────────┬─────────────┐
     │           │           │             │
┌────▼─────┐ ┌──▼───┐  ┌────▼────┐  ┌────▼─────────┐
│ MongoDB  │ │Redis │  │ Sandbox │  │ Bull Queue   │
│ Atlas    │ │Cloud │  │(Docker)  │  │ (Redis)      │
│          │ │      │  │          │  │              │
│-Users    │ │-Cache│  │-Isolated │  │-Submissions  │
│-Contests │ │-Sessions│ │execution│  │-Jobs         │
│-Problems │ │-Leaderboard│        │  │              │
│-Submissions│      │  │          │  │              │
└──────────┘ └──────┘  └──────────┘  └──────────────┘
```

### 10.2 Specific Deployment Steps

**1. MongoDB Atlas Setup:**
```
→ Create cluster (M0 free or M10+ for production)
→ Configure network access:
  - Add backend server IP
  - Add your development IP
→ Create database: devflow
→ Collections will auto-create
→ Setup indexes:
  - User: username, email
  - Contest: customUrl, status, startTime
  - Problem: slug
  - Submission: userId+contestId, status
→ Get connection string
→ Store in environment variables
```

**2. Redis Cloud Setup:**
```
→ Create Redis instance (free 30MB or paid)
→ Get connection URL: redis://user:password@host:port
→ Configure for:
  - Leaderboard cache (sorted sets)
  - Session storage
  - Bull queue
→ Set eviction policy: allkeys-lru
→ Store URL in environment variables
```

**3. Backend Deployment (Render):**
```
→ Connect GitHub repository
→ Configure build settings:
  - Build Command: npm install
  - Start Command: npm start
→ Set environment variables:
  PORT=10000
  NODE_ENV=production
  MONGODB_URI=mongodb+srv://...
  REDIS_URL=redis://...
  JWT_SECRET=your-secret
  GEMINI_API_KEY=your-key
  CLIENT_URL=https://devflow.vercel.app
  SANDBOX_URL=https://sandbox-service-url
→ Choose instance type (Standard for production)
→ Deploy
→ Get backend URL: https://devflow-api.onrender.com
```

**4. Sandbox Deployment (Separate Service):**

**Option A: Same server as backend with Docker installed**
```
On Render or Railway:
→ Ensure Docker is available
→ Your sandbox runs as a separate Express service
→ Expose on different port (3001)
→ Backend makes HTTP requests to sandbox

Dockerfile for sandbox:
FROM node:16-alpine
RUN apk add --no-cache docker
WORKDIR /app
COPY sandbox/package*.json ./
RUN npm ci
COPY sandbox/ .
EXPOSE 3001
CMD ["npm", "start"]
```

**Option B: Separate Docker container orchestration**
```
Using Railway with Docker:
→ Deploy sandbox as separate service
→ Enable inter-service communication
→ Sandbox can spin up Docker containers
→ Set resource limits in Railway dashboard
```

**5. Frontend Deployment (Vercel):**
```
→ Connect GitHub repository
→ Framework: Create React App
→ Build Command: npm run build
→ Output Directory: build
→ Environment Variables:
  REACT_APP_API_URL=https://devflow-api.onrender.com
  REACT_APP_SOCKET_URL=https://devflow-api.onrender.com
→ Deploy
→ Custom domain: devflow.vercel.app
→ Auto-deploy on git push to main
```

**6. Domain & SSL Setup:**
```
Backend (api.devflow.com):
→ Add custom domain in Render
→ Update DNS CNAME record
→ Render auto-provisions SSL

Frontend (devflow.com):
→ Add custom domain in Vercel
→ Update DNS A/CNAME records
→ Vercel auto-provisions SSL
```

### 10.3 Production Configuration

**Backend Production Optimizations:**
```javascript
// server.js for production

if (process.env.NODE_ENV === 'production') {
  // Trust proxy
  app.set('trust proxy', 1);
  
  // Rate limiting
  const limiter = rateLimit({
    windowMs: 15 * 60 * 1000, // 15 minutes
    max: 100 // limit each IP to 100 requests per windowMs
  });
  app.use('/api/', limiter);
  
  // Compression
  app.use(compression());
  
  // Security headers
  app.use(helmet({
    contentSecurityPolicy: false, // Configure as needed
  }));
  
  // CORS for production
  app.use(cors({
    origin: process.env.CLIENT_URL,
    credentials: true
  }));
  
  // MongoDB connection pool
  mongoose.connect(process.env.MONGODB_URI, {
    maxPoolSize: 50,
    minPoolSize: 10,
    serverSelectionTimeoutMS: 5000,
    socketTimeoutMS: 45000,
  });
}
```

---

## PHASE 11: TESTING STRATEGY

### 11.1 Testing Flow for Each Component

**Backend API Tests:**
```
Test Structure:
tests/
├── unit/
│   ├── models/
│   │   ├── User.test.js
│   │   ├── Contest.test.js
│   │   └── Problem.test.js
│   ├── services/
│   │   ├── auth.test.js
│   │   ├── leaderboard.test.js
│   │   └── scraper.test.js
│   └── utils/
│       └── validators.test.js
├── integration/
│   ├── auth.test.js
│   ├── contests.test.js
│   ├── submissions.test.js
│   └── leaderboard.test.js
└── e2e/
    └── contest-flow.test.js

Example Test Flow (Contest Creation):

describe('POST /api/contests', () => {
  beforeAll(async () => {
    // Connect to test database
    await mongoose.connect(TEST_DB_URI);
  });
  
  beforeEach(async () => {
    // Clear database
    await Contest.deleteMany({});
    // Create test admin user
    admin = await User.create({...adminData});
    token = admin.generateAuthToken();
  });
  
  it('should create contest with valid data', async () => {
    const res = await request(app)
      .post('/api/contests')
      .set('Authorization', `Bearer ${token}`)
      .send({
        title: 'Test Contest',
        description: 'Description',
        customUrl: 'test-contest',
        startTime: new Date(Date.now() + 3600000),
        duration: 120
      });
    
    expect(res.status).toBe(201);
    expect(res.body.contest.title).toBe('Test Contest');
    
    // Verify in database
    const contest = await Contest.findOne({ customUrl: 'test-contest' });
    expect(contest).toBeTruthy();
  });
  
  it('should reject duplicate customUrl', async () => {
    await Contest.create({ customUrl: 'test-contest', ... });
    
    const res = await request(app)
      .post('/api/contests')
      .set('Authorization', `Bearer ${token}`)
      .send({ customUrl: 'test-contest', ... });
    
    expect(res.status).toBe(400);
    expect(res.body.error).toContain('already exists');
  });
  
  it('should reject non-admin users', async () => {
    const user = await User.create({...userData, role: 'participant'});
    const userToken = user.generateAuthToken();
    
    const res = await request(app)
      .post('/api/contests')
      .set('Authorization', `Bearer ${userToken}`)
      .send({...validContestData});
    
    expect(res.status).toBe(403);
  });
});
```

**Sandbox Integration Tests:**
```
Since your sandbox is already implemented, test:

describe('Sandbox Execution', () => {
  it('should execute Python code correctly', async () => {
    const code = `
      a, b = map(int, input().split())
      print(a + b)
    `;
    
    const res = await request(SANDBOX_URL)
      .post('/api/sandbox/run')
      .send({
        code,
        language: 'python',
        testCases: [
          { input: '2 3', expectedOutput: '5' }
        ],
        limits: { timeLimit: 2000, memoryLimit: 256 }
      });
    
    expect(res.body.testCaseResults[0].passed).toBe(true);
  });
  
  it('should detect TLE', async () => {
    const code = `
      import time
      time.sleep(5)
      print("Done")
    `;
    
    const res = await request(SANDBOX_URL)
      .post('/api/sandbox/run')
      .send({
        code,
        language: 'python',
        limits: { timeLimit: 1000 }
      });
    
    expect(res.body.status).toBe('TLE');
  });
  
  it('should enforce memory limits', async () => {
    const code = `
      a = [0] * (10**8)  # Try to allocate ~400MB
      print("Done")
    `;
    
    const res = await request(SANDBOX_URL)
      .post('/api/sandbox/run')
      .send({
        code,
        language: 'python',
        limits: { memoryLimit: 128 }
      });
    
    expect(res.body.status).toMatch(/MLE|RE/);
  });
});
```

**Frontend Component Tests:**
```
Using React Testing Library:

describe('CodeEditor', () => {
  it('should render Monaco editor', () => {
    render(<CodeEditor />);
    expect(screen.getByRole('textbox')).toBeInTheDocument();
  });
  
  it('should save code to localStorage on change', async () => {
    render(<CodeEditor contestId="123" problemId="456" />);
    const editor = screen.getByRole('textbox');
    
    fireEvent.change(editor, { target: { value: 'print("Hello")' } });
    
    await waitFor(() => {
      const saved = localStorage.getItem('code-123-456-python');
      expect(saved).toBe('print("Hello")');
    });
  });
  
  it('should disable submit during judging', async () => {
    render(<CodeEditor />);
    const submitBtn = screen.getByText('Submit');
    
    fireEvent.click(submitBtn);
    
    expect(submitBtn).toBeDisabled();
    expect(submitBtn).toHaveTextContent('Judging...');
  });
});
```

**E2E Tests with Cypress:**
```javascript
describe('Contest Participation Flow', () => {
  beforeEach(() => {
    // Seed database with test contest
    cy.task('seed:db', { contest: testContest });
  });
  
  it('user can register and participate in contest', () => {
    // Login
    cy.visit('/login');
    cy.get('[name=email]').type('user@test.com');
    cy.get('[name=password]').type('password');
    cy.get('button[type=submit]').click();
    
    // Navigate to contest
    cy.visit('/contest/test-contest-123');
    cy.get('button').contains('Register').click();
    cy.get('button').contains('Confirm').click();
    
    // Enter contest
    cy.get('button').contains('Enter Contest').click();
    
    // Select problem
    cy.get('[data-testid=problem-1]').click();
    
    // Write code
    cy.get('.monaco-editor').type('def solve():\n    return 42');
    
    // Submit
    cy.get('button').contains('Submit').click();
    cy.get('button').contains('Confirm Submit').click();
    
    // Wait for result
    cy.get('[data-testid=submission-result]', { timeout: 10000 })
      .should('be.visible');
    
    // Check leaderboard updated
    cy.visit('/contest/test-contest-123/leaderboard');
    cy.contains('user@test.com').should('be.visible');
  });
});
```

---

## SUMMARY OF IMPLEMENTATION SEQUENCE

**Week 1-2: Core Foundation**
1. Setup authentication system (JWT, bcrypt)
2. Create user management (register, login, profile)
3. Setup MongoDB schemas (User, Contest, Problem, Submission)
4. Implement role-based access control

**Week 3-4: Contest & Problem Management**
1. Build contest CRUD operations
2. Integrate your existing scraper for problem import
3. Implement manual problem creation
4. Setup contest scheduling with cron jobs
5. Link problems to contests

**Week 5-6: Code Execution Pipeline**
1. Integrate your existing sandbox service
2. Setup Bull queue for submission processing
3. Implement submission controller
4. Connect sandbox results to database
5. Handle all verdict types (AC, WA, TLE, RE, CE)

**Week 7: Real-Time Features**
1. Setup Socket.io server
2. Implement room management
3. Create real-time leaderboard with Redis
4. Add live submission updates
5. Implement notification system

**Week 8: Anti-Cheat System**
1. Frontend monitoring (tab switch, copy-paste)
2. Backend violation tracking
3. Warning and lock mechanisms
4. Admin monitoring dashboard

**Week 9: Frontend Development**
1. Build authentication pages
2. Create contest list and details pages
3. Develop contest arena with Monaco Editor
4. Implement leaderboard UI
5. Build admin dashboard
6. Add real-time updates via Socket.io

**Week 10: Testing & Deployment**
1. Write unit and integration tests
2. Setup CI/CD pipeline
3. Deploy to production (Render + Vercel)
4. Configure monitoring and logging
5. Performance optimization

This technical flow leverages your existing sandbox and scraper components while building the complete platform around them. Focus on solid integration between these components and the new systems you'll build.